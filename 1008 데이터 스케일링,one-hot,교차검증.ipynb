{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분류\n",
    "# 정규화를 하지않고 데이터를 분류\n",
    "x_train, x_test, y_train, y_test =train_test_split(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential(name=\"test1\")\n",
    "    model.add(Dense(16,input_shape=(4,),activation=\"relu\" ) )\n",
    "    model.add(Dense(16,activation=\"relu\"))\n",
    "    model.add(Dense(3,activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"acc\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 싸이킷런과 연동되어 쓸 수 있는 모델을 생성\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화가 되지 않은 모델\n",
    "kc1 = KerasClassifier(build_model,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 1.9409 - acc: 0.0714\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 1.8067 - acc: 0.1339\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 1.6707 - acc: 0.1607\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 0s 54us/sample - loss: 1.5651 - acc: 0.0982\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.4755 - acc: 0.1696\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 0s 54us/sample - loss: 1.4066 - acc: 0.3036\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 0s 54us/sample - loss: 1.3427 - acc: 0.3214\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.2810 - acc: 0.3661\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.2329 - acc: 0.3661\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.1781 - acc: 0.3661\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.1413 - acc: 0.3661\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.1103 - acc: 0.3661\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.0858 - acc: 0.3661\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.0614 - acc: 0.3839\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 1.0433 - acc: 0.3839\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0205 - acc: 0.4018\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0009 - acc: 0.3929\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 0.9858 - acc: 0.3929\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.9662 - acc: 0.4375\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.9457 - acc: 0.6250\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.9272 - acc: 0.7054\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.9085 - acc: 0.7143\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.8911 - acc: 0.7411\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.8722 - acc: 0.7411\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.8535 - acc: 0.7411\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.8366 - acc: 0.7679\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.8195 - acc: 0.7768\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.8016 - acc: 0.7857\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.7845 - acc: 0.7857\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.7680 - acc: 0.7411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a115188>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kc1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫 인코딩과 데이터를 정규화후 싸이킷런과 연계된 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 모델 생성\n",
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화 모델 생성\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max 모델\n",
    "# 데이터를 일반적으로 0~1 사이의 값으로 변환시켜준다.\n",
    "# 데이터의 최소값, 최대값을 알 경우 사용한다.\n",
    "iris_norm = mm.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "# 제로 평균 으로부터 각 값들의 분산을 나타낸다\n",
    "# 스케일이 다른 변수들을 비교할때 사용\n",
    "# 기존 변수에 범위를 정규 분포로 변환한다.\n",
    "iris_norm1 = ss.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "# 정규화는 데이터의 범위를 0과 1로 변환하여 데이터 분포를 조정하는 방법이다. \n",
    "iris_norm2 = nn.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris_norm,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화\n",
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(iris_norm1,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "x_train2,x_test2,y_train2,y_test2 = train_test_split(iris_norm2,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스 유틸을 사용\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot 인코딩\n",
    "y_train_one = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot 인코딩\n",
    "y_train_one1 = to_categorical(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot 인코딩\n",
    "y_train_one2 = to_categorical(y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1():\n",
    "    model = Sequential(name=\"gkdl\")\n",
    "    model.add(Dense(16,input_shape=(4,),activation=\"relu\" ) )\n",
    "    model.add(Dense(16,activation=\"relu\"))\n",
    "    model.add(Dense(3,activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "kc2 = KerasClassifier(build_fn = build_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.1156 - acc: 0.3214\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 1.1084 - acc: 0.3214\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.1029 - acc: 0.3214\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.0973 - acc: 0.3661\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0919 - acc: 0.4732\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.0863 - acc: 0.5982\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.0812 - acc: 0.6429\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.0757 - acc: 0.6786\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.0703 - acc: 0.6786\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.0650 - acc: 0.6786\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.0596 - acc: 0.6786\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.0544 - acc: 0.6786\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0485 - acc: 0.6786\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 1.0419 - acc: 0.6786\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.0356 - acc: 0.6786\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0296 - acc: 0.6786\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 1.0223 - acc: 0.6786\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0151 - acc: 0.6786\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0077 - acc: 0.6786\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 1.0002 - acc: 0.6786\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.9925 - acc: 0.6786\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.9845 - acc: 0.6786\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.9763 - acc: 0.6786\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.9676 - acc: 0.6786\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.9591 - acc: 0.6786\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.9494 - acc: 0.6786\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.9392 - acc: 0.6786\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.9274 - acc: 0.6786\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.9137 - acc: 0.6786\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.9003 - acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2f95f188>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min-max 모델\n",
    "kc2.fit(x_train,y_train_one,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.1212 - acc: 0.2143\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0935 - acc: 0.2500\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0668 - acc: 0.3393\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0406 - acc: 0.4375\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.0135 - acc: 0.5357\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 0s 54us/sample - loss: 0.9878 - acc: 0.5714\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.9610 - acc: 0.6607\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.9337 - acc: 0.7054\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.9055 - acc: 0.7321\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.8786 - acc: 0.7411\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.8528 - acc: 0.7857\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.8253 - acc: 0.8036\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.8008 - acc: 0.8304\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.7790 - acc: 0.8482\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.7551 - acc: 0.8482\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.7352 - acc: 0.8571\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.7160 - acc: 0.8750\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.6973 - acc: 0.8750\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.6796 - acc: 0.8750\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.6632 - acc: 0.8571\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 0.6465 - acc: 0.8571\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.6301 - acc: 0.8661\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.6140 - acc: 0.8571\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.5975 - acc: 0.8393\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 0.5817 - acc: 0.8571\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.5659 - acc: 0.8482\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.5500 - acc: 0.8661\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.5351 - acc: 0.8929\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 80us/sample - loss: 0.5198 - acc: 0.8929\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.5050 - acc: 0.9018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x30529488>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표준화\n",
    "kc2.fit(x_train1,y_train_one1,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples\n",
      "Epoch 1/30\n",
      "112/112 [==============================] - 1s 9ms/sample - loss: 1.1387 - acc: 0.3214\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 0s 63us/sample - loss: 1.1286 - acc: 0.3214\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 1.1215 - acc: 0.3214\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 0s 71us/sample - loss: 1.1149 - acc: 0.3214\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 1.1094 - acc: 0.3214\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.1033 - acc: 0.3214\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0990 - acc: 0.3214\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 1.0942 - acc: 0.3214\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 0s 89us/sample - loss: 1.0904 - acc: 0.3214\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 1.0876 - acc: 0.3214\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0838 - acc: 0.3482\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 0s 170us/sample - loss: 1.0805 - acc: 0.6518\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0770 - acc: 0.6875\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0740 - acc: 0.6875\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.0703 - acc: 0.6875\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 1.0668 - acc: 0.6875\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 1.0630 - acc: 0.6875\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 1.0591 - acc: 0.6875\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - ETA: 0s - loss: 1.0665 - acc: 0.625 - 0s 143us/sample - loss: 1.0549 - acc: 0.6875\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 1.0504 - acc: 0.6875\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 1.0454 - acc: 0.6875\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 1.0394 - acc: 0.6875\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 1.0339 - acc: 0.6875\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0274 - acc: 0.6875\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 1.0209 - acc: 0.6875\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 1.0143 - acc: 0.6875\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 1.0067 - acc: 0.6875\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 0.9998 - acc: 0.6875\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 0s 98us/sample - loss: 0.9925 - acc: 0.6875\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.9841 - acc: 0.6875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x30f47588>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규화\n",
    "kc2.fit(x_train2,y_train_one2,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "from sklearn.model_selection import cross_validate,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples\n",
      "100/100 [==============================] - 0s 5ms/sample - loss: 1.0509 - acc: 0.3700\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 15ms/sample - loss: 1.0610 - acc: 0.2500\n",
      "Train on 100 samples\n",
      "100/100 [==============================] - 1s 7ms/sample - loss: 1.0513 - acc: 0.3400\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 1.0663 - acc: 0.1667\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 6ms/sample - loss: 1.0655 - acc: 0.3366\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 17ms/sample - loss: 1.0581 - acc: 0.0909\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 6ms/sample - loss: 1.1001 - acc: 0.3465\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 1.0924 - acc: 0.1818\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 6ms/sample - loss: 1.1036 - acc: 0.3762\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 1.1101 - acc: 0.2727\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 11ms/sample - loss: 1.0225 - acc: 0.3168\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 12ms/sample - loss: 1.0158 - acc: 0.3636\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 0s 5ms/sample - loss: 1.1311 - acc: 0.3762\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 15ms/sample - loss: 1.1912 - acc: 0.1818\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 6ms/sample - loss: 1.0829 - acc: 0.3663\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 1.0701 - acc: 0.4545\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 0s 4ms/sample - loss: 1.1397 - acc: 0.3267\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 1.0974 - acc: 0.5455\n",
      "Train on 101 samples\n",
      "101/101 [==============================] - 1s 6ms/sample - loss: 1.0910 - acc: 0.3366\n",
      "11/1 [==========================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 1.1559 - acc: 0.1818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.25      , 0.16666667, 0.09090909, 0.18181819, 0.27272728,\n",
       "       0.36363637, 0.18181819, 0.45454547, 0.54545456, 0.18181819])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(kc2,x_train,y_train, cv = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
